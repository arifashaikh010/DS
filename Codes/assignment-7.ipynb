{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d805199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Text Analytics\n",
    "#1.Extract Sample document and apply following document preprocessing methods:Tokenization, POS Tagging, stop words removal, \n",
    "#Stemming andLemmatization.\n",
    "#2.Create representation of document by calculating Term Frequency and InverseDocumentFrequency.\n",
    "\n",
    "#no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06d535e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "628bbcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\arifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\arifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Error loading averged_perception_tagger: Package\n",
      "[nltk_data]     'averged_perception_tagger' not found in index\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averged_perception_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44d8b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1352417",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent= \"They told that thier eges are 20 23 and 27 respectively\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07151f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a75b5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sent.split():\n",
    "    if word.isdigit():\n",
    "        add.append(int(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fdc4a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave 23.333333333333332\n"
     ]
    }
   ],
   "source": [
    "print (\"Ave\", sum(add)/len(add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbe57db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfe720ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent= \"Hello all! how are you? Welcome to pun \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "defa044c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello all!', 'how are you?', 'Welcome to pun']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9982874e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'all', '!', 'how', 'are', 'you', '?', 'Welcome', 'to', 'pun']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abfad924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'all!', 'how', 'are', 'you?', 'Welcome', 'to', 'pun', '']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import SpaceTokenizer\n",
    "tk=SpaceTokenizer()\n",
    "tk.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d650aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent='Hello all!\\tHow are u?\\tto pune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba452474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello all!\tHow are u?\tto pune\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d2a5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1='ctas','catlike','catty','cat'\n",
    "s2='stemmer','stemming','stemmed','stem'\n",
    "s3='fishing','fished','fisher','fish'\n",
    "s4='argue','argued','argues','argus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93cd94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "627b346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98d4fc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fish'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(s3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c16f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respect\n"
     ]
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c9c2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "823c9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word='playing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fba476e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0808583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "691519b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing\n",
      "play\n",
      "playing\n",
      "playing\n"
     ]
    }
   ],
   "source": [
    "print(wnl.lemmatize(word,'n')) # noun\n",
    "print(wnl.lemmatize(word,'v')) # verb\n",
    "print(wnl.lemmatize(word,'a')) # adjective\n",
    "print(wnl.lemmatize(word,'r')) # adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b602c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word='went'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb2f1575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went\n",
      "go\n",
      "went\n",
      "went\n"
     ]
    }
   ],
   "source": [
    "wnl=WordNetLemmatizer()\n",
    "print(wnl.lemmatize(word,'n')) # noun\n",
    "print(wnl.lemmatize(word,'v')) # verb\n",
    "print(wnl.lemmatize(word,'a')) # adjective\n",
    "print(wnl.lemmatize(word,'r')) # adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64987b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0993bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6037e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\arifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3d64cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents='Rajgad (literal meaning Ruling Fort) is a hill fort situated in the Pune district of Maharashtra, India. Formerly known as Murumde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07a7ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rajgad (literal meaning Ruling Fort) is a hill fort situated in the Pune district of Maharashtra, India. Formerly known as Murumde\n"
     ]
    }
   ],
   "source": [
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0cdc6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word_tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a55fec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\arifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2c47502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rajgad', 'NNP'),\n",
       " ('(', '('),\n",
       " ('literal', 'JJ'),\n",
       " ('meaning', 'NN'),\n",
       " ('Ruling', 'NNP'),\n",
       " ('Fort', 'NNP'),\n",
       " (')', ')'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('hill', 'NN'),\n",
       " ('fort', 'NN'),\n",
       " ('situated', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Pune', 'NNP'),\n",
       " ('district', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Maharashtra', 'NNP'),\n",
       " (',', ','),\n",
       " ('India', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Formerly', 'RB'),\n",
       " ('known', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('Murumde', 'NNP')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70342e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31295877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "situated\n",
      "known\n"
     ]
    }
   ],
   "source": [
    "for word in tags:\n",
    "    if word[1].startswith('V'):\n",
    "        print(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64f8cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4723cef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1432\\601046462.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# spell correction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "# spell correction\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f89702f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1432\\2196745319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'computoor'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "t=TextBlob('computoor')\n",
    "print(t.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4bbe4fa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1432\\3224985225.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nead'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "t=TextBlob('nead')\n",
    "print(t.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b78770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
